{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import multiprocessing as mp\n",
    "import statistics\n",
    "\n",
    "import librosa\n",
    "from librosa import feature\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# tensorflow libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# sklearn libraries are useful for preprocessing, performance measures, etc.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rootdir = '/Users/abhishekvaidyanathan/Desktop/NNDL-project/audio-files'\n",
    "rootdir = '/Users/abhishekvaidyanathan/Desktop/NNDL-project/audio-files'\n",
    "audio_files = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        audio_files.append(os.path.join(subdir, file))\n",
    "audio_files = audio_files[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Actor_16'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_files[1][-33:-25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_actors = {}\n",
    "for audio_file in audio_files:\n",
    "    try :\n",
    "        if (len(dict_actors[audio_file[-33:-25]])>0):\n",
    "            dict_actors[audio_file[-33:-25]].append(audio_file)\n",
    "    except:\n",
    "        dict_actors[audio_file[-33:-25]] = []\n",
    "        dict_actors[audio_file[-33:-25]].append(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns = ['Actor','Modality','Vocal_channel','Emotion','Emotional_intensity','Statement','Repetion','Gender','Audio_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(value):\n",
    "    if(int(value)%2==0):\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "for keys in dict_actors:\n",
    "    for files in dict_actors[keys]:\n",
    "        data.loc[len(data)] = [keys,int(files[-24:-22]),int(files[-21:-19]),int(files[-18:-16]),int(files[-15:-13]),int(files[-12:-10]),int(files[-9:-7]),get_gender(files[-6:-4]),files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actor</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Vocal_channel</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotional_intensity</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Repetion</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Audio_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actor_16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/abhishekvaidyanathan/Desktop/NNDL-proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor_16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/abhishekvaidyanathan/Desktop/NNDL-proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Actor_16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/abhishekvaidyanathan/Desktop/NNDL-proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actor_16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/abhishekvaidyanathan/Desktop/NNDL-proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Actor_16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/abhishekvaidyanathan/Desktop/NNDL-proje...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actor Modality Vocal_channel Emotion Emotional_intensity Statement  \\\n",
       "0  Actor_16        3             1       5                   1         2   \n",
       "1  Actor_16        3             1       6                   1         2   \n",
       "2  Actor_16        3             1       6                   2         1   \n",
       "3  Actor_16        3             1       5                   2         1   \n",
       "4  Actor_16        3             1       7                   1         1   \n",
       "\n",
       "  Repetion Gender                                         Audio_file  \n",
       "0        1      1  /Users/abhishekvaidyanathan/Desktop/NNDL-proje...  \n",
       "1        2      1  /Users/abhishekvaidyanathan/Desktop/NNDL-proje...  \n",
       "2        2      1  /Users/abhishekvaidyanathan/Desktop/NNDL-proje...  \n",
       "3        1      1  /Users/abhishekvaidyanathan/Desktop/NNDL-proje...  \n",
       "4        1      1  /Users/abhishekvaidyanathan/Desktop/NNDL-proje...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## can change the below code cell to include different set of features. \n",
    "\n",
    "#### right now uses mean values, can change to using raw values for each of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2803.66001659 1379.6672431  1562.99924373 ... 2549.85781492\n",
      "  2456.23949636 2515.19654634]]\n",
      "(1, 2647)\n",
      "1364.8838771312614\n"
     ]
    }
   ],
   "source": [
    "# y, sr = librosa.load(librosa.util.example_audio_file())\n",
    "# temp_func = feature.spectral_bandwidth\n",
    "# temp_res = temp_func(y=y, sr=sr)\n",
    "# print(temp_res)\n",
    "# print(temp_res.shape)\n",
    "# print(np.mean(temp_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add:\n",
    "# mfcc - use n_mfcc=13 and take mean along axis 1 [13 features]\n",
    "# chroma_stft - take mean along axis 1 [12 features]\n",
    "# librosa.onset.onset_strength(y=y, sr=sr) - take direct mean\n",
    "# zero_crossing_rate - take direct mean\n",
    "# spectral_rolloff - direct mean\n",
    "# librosa.piptrack - returns pitch and magnitude, take direct means of both\n",
    "# melspectrogram - take direct mean\n",
    "# spectral_contrast - use axis=1 [7 features]\n",
    "# tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0) [6 features]\n",
    "# rms - take direct mean\n",
    "# spectral_centroid - take direct mean\n",
    "# spectral_bandwidth - take direct mean\n",
    "\n",
    "\n",
    "def get_feature_vector(y, sr):\n",
    "    feature_vector = []\n",
    "    \n",
    "    # multi-dim features\n",
    "    feature_vector.extend(np.mean(feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1))\n",
    "    feature_vector.extend(np.mean(feature.chroma_stft(y=y, sr=sr), axis=1))\n",
    "    feature_vector.extend(np.mean(feature.spectral_contrast(y=y, sr=sr), axis=1))\n",
    "    feature_vector.extend(np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr),axis=1))\n",
    "    \n",
    "    # single-dim features with special requirements\n",
    "    feature_vector.append(np.mean(feature.rms(y=y)))\n",
    "    feature_vector.append(np.mean(feature.zero_crossing_rate(y=y)))\n",
    "    feature_vector.extend([np.mean(x) for x in librosa.piptrack(y=y, sr=sr)])\n",
    "    \n",
    "    # single-dim features\n",
    "    feat_list = [\n",
    "        librosa.onset.onset_strength,\n",
    "        feature.spectral_rolloff,\n",
    "        feature.melspectrogram,\n",
    "        feature.spectral_centroid,\n",
    "        feature.spectral_bandwidth\n",
    "    ]\n",
    "    \n",
    "    for temp_func in feat_list:\n",
    "        feature_vector.append(np.mean(temp_func(y=y, sr=sr)))\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = []\n",
    "for i in range(data.shape[0]):\n",
    "   y , sr = librosa.load(data.iloc[i]['Audio_file'],sr=None)\n",
    "   feature_vector = get_feature_vector(y, sr)\n",
    "   audio_features.append(feature_vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = data_features.drop(\"Audio_file\",axis=1)\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features['librosa'] = audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(data_features['librosa'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement1 = 'Kids are talking by the door'\n",
    "statement2 = 'Dogs are sitting by the door'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-719.127808</td>\n",
       "      <td>70.202240</td>\n",
       "      <td>1.169071</td>\n",
       "      <td>13.123216</td>\n",
       "      <td>7.837617</td>\n",
       "      <td>14.411950</td>\n",
       "      <td>-4.110705</td>\n",
       "      <td>4.469619</td>\n",
       "      <td>-3.538730</td>\n",
       "      <td>-3.657982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.052904</td>\n",
       "      <td>40.032833</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.992758</td>\n",
       "      <td>13191.718251</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>7135.753114</td>\n",
       "      <td>5653.712371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-714.994934</td>\n",
       "      <td>69.690376</td>\n",
       "      <td>3.925557</td>\n",
       "      <td>11.925324</td>\n",
       "      <td>6.423343</td>\n",
       "      <td>11.014113</td>\n",
       "      <td>-2.874456</td>\n",
       "      <td>4.514386</td>\n",
       "      <td>-4.470305</td>\n",
       "      <td>-2.665093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.046627</td>\n",
       "      <td>37.690022</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.860653</td>\n",
       "      <td>13280.282980</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>7240.619346</td>\n",
       "      <td>5640.892215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-710.959839</td>\n",
       "      <td>67.579193</td>\n",
       "      <td>5.783356</td>\n",
       "      <td>13.227695</td>\n",
       "      <td>6.194669</td>\n",
       "      <td>12.640195</td>\n",
       "      <td>-1.662046</td>\n",
       "      <td>5.663977</td>\n",
       "      <td>-4.953693</td>\n",
       "      <td>-3.484669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.053835</td>\n",
       "      <td>39.524185</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.918893</td>\n",
       "      <td>13273.018037</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>7009.490125</td>\n",
       "      <td>5802.602446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-759.917847</td>\n",
       "      <td>75.788948</td>\n",
       "      <td>6.028997</td>\n",
       "      <td>14.562723</td>\n",
       "      <td>6.459432</td>\n",
       "      <td>14.636641</td>\n",
       "      <td>-2.999552</td>\n",
       "      <td>4.625813</td>\n",
       "      <td>-5.195350</td>\n",
       "      <td>-0.702961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>38.651924</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.988106</td>\n",
       "      <td>12649.614081</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>6997.114097</td>\n",
       "      <td>5518.781643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-735.006592</td>\n",
       "      <td>79.093056</td>\n",
       "      <td>8.141059</td>\n",
       "      <td>11.413560</td>\n",
       "      <td>5.174132</td>\n",
       "      <td>15.393293</td>\n",
       "      <td>-2.752063</td>\n",
       "      <td>2.964593</td>\n",
       "      <td>-5.388961</td>\n",
       "      <td>-1.691822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032999</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.033038</td>\n",
       "      <td>43.064930</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.899759</td>\n",
       "      <td>12202.824519</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>6874.562103</td>\n",
       "      <td>5416.338418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2          3         4          5         6   \\\n",
       "0 -719.127808  70.202240  1.169071  13.123216  7.837617  14.411950 -4.110705   \n",
       "1 -714.994934  69.690376  3.925557  11.925324  6.423343  11.014113 -2.874456   \n",
       "2 -710.959839  67.579193  5.783356  13.227695  6.194669  12.640195 -1.662046   \n",
       "3 -759.917847  75.788948  6.028997  14.562723  6.459432  14.636641 -2.999552   \n",
       "4 -735.006592  79.093056  8.141059  11.413560  5.174132  15.393293 -2.752063   \n",
       "\n",
       "         7         8         9   ...        37        38        39         40  \\\n",
       "0  4.469619 -3.538730 -3.657982  ...  0.004175  0.002258  0.052904  40.032833   \n",
       "1  4.514386 -4.470305 -2.665093  ...  0.016821  0.002707  0.046627  37.690022   \n",
       "2  5.663977 -4.953693 -3.484669  ...  0.011100  0.002521  0.053835  39.524185   \n",
       "3  4.625813 -5.195350 -0.702961  ...  0.002851  0.001579  0.045929  38.651924   \n",
       "4  2.964593 -5.388961 -1.691822  ...  0.032999  0.001676  0.033038  43.064930   \n",
       "\n",
       "         41        42            43        44           45           46  \n",
       "0  0.002662  0.992758  13191.718251  0.003416  7135.753114  5653.712371  \n",
       "1  0.003359  0.860653  13280.282980  0.004721  7240.619346  5640.892215  \n",
       "2  0.003164  0.918893  13273.018037  0.004341  7009.490125  5802.602446  \n",
       "3  0.001842  0.988106  12649.614081  0.001624  6997.114097  5518.781643  \n",
       "4  0.002004  0.899759  12202.824519  0.001781  6874.562103  5416.338418  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439, 47)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_labels = pd.Series([int(x[-2:]) for x in data['Actor']], name='Actor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_values = features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaled_values = min_max_scaler.fit_transform(features_values)\n",
    "features_normalised = pd.DataFrame(features_scaled_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285469</td>\n",
       "      <td>0.532704</td>\n",
       "      <td>0.711228</td>\n",
       "      <td>0.566807</td>\n",
       "      <td>0.698543</td>\n",
       "      <td>0.659506</td>\n",
       "      <td>0.644720</td>\n",
       "      <td>0.642219</td>\n",
       "      <td>0.649567</td>\n",
       "      <td>0.615905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490164</td>\n",
       "      <td>0.021892</td>\n",
       "      <td>0.178884</td>\n",
       "      <td>0.686954</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>0.232647</td>\n",
       "      <td>0.850756</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.897211</td>\n",
       "      <td>0.802389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.293124</td>\n",
       "      <td>0.527383</td>\n",
       "      <td>0.748110</td>\n",
       "      <td>0.544651</td>\n",
       "      <td>0.666486</td>\n",
       "      <td>0.574399</td>\n",
       "      <td>0.675547</td>\n",
       "      <td>0.643559</td>\n",
       "      <td>0.615851</td>\n",
       "      <td>0.650318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621171</td>\n",
       "      <td>0.026986</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.643590</td>\n",
       "      <td>0.026162</td>\n",
       "      <td>0.091577</td>\n",
       "      <td>0.859952</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.917975</td>\n",
       "      <td>0.798843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.300599</td>\n",
       "      <td>0.505434</td>\n",
       "      <td>0.772967</td>\n",
       "      <td>0.568739</td>\n",
       "      <td>0.661303</td>\n",
       "      <td>0.615128</td>\n",
       "      <td>0.705780</td>\n",
       "      <td>0.677990</td>\n",
       "      <td>0.598355</td>\n",
       "      <td>0.621912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561902</td>\n",
       "      <td>0.024872</td>\n",
       "      <td>0.185497</td>\n",
       "      <td>0.677539</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>0.153769</td>\n",
       "      <td>0.859198</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.872211</td>\n",
       "      <td>0.843582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209913</td>\n",
       "      <td>0.590785</td>\n",
       "      <td>0.776254</td>\n",
       "      <td>0.593432</td>\n",
       "      <td>0.667304</td>\n",
       "      <td>0.665134</td>\n",
       "      <td>0.672428</td>\n",
       "      <td>0.646897</td>\n",
       "      <td>0.589609</td>\n",
       "      <td>0.718323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476445</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.129345</td>\n",
       "      <td>0.661394</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.227678</td>\n",
       "      <td>0.794469</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.869760</td>\n",
       "      <td>0.765059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256056</td>\n",
       "      <td>0.625135</td>\n",
       "      <td>0.804513</td>\n",
       "      <td>0.535186</td>\n",
       "      <td>0.638171</td>\n",
       "      <td>0.684086</td>\n",
       "      <td>0.678599</td>\n",
       "      <td>0.597143</td>\n",
       "      <td>0.582602</td>\n",
       "      <td>0.684050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788763</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.037792</td>\n",
       "      <td>0.743076</td>\n",
       "      <td>0.014689</td>\n",
       "      <td>0.133337</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.736717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.285469  0.532704  0.711228  0.566807  0.698543  0.659506  0.644720   \n",
       "1  0.293124  0.527383  0.748110  0.544651  0.666486  0.574399  0.675547   \n",
       "2  0.300599  0.505434  0.772967  0.568739  0.661303  0.615128  0.705780   \n",
       "3  0.209913  0.590785  0.776254  0.593432  0.667304  0.665134  0.672428   \n",
       "4  0.256056  0.625135  0.804513  0.535186  0.638171  0.684086  0.678599   \n",
       "\n",
       "         7         8         9   ...        37        38        39        40  \\\n",
       "0  0.642219  0.649567  0.615905  ...  0.490164  0.021892  0.178884  0.686954   \n",
       "1  0.643559  0.615851  0.650318  ...  0.621171  0.026986  0.134300  0.643590   \n",
       "2  0.677990  0.598355  0.621912  ...  0.561902  0.024872  0.185497  0.677539   \n",
       "3  0.646897  0.589609  0.718323  ...  0.476445  0.014187  0.129345  0.661394   \n",
       "4  0.597143  0.582602  0.684050  ...  0.788763  0.015293  0.037792  0.743076   \n",
       "\n",
       "         41        42        43        44        45        46  \n",
       "0  0.020258  0.232647  0.850756  0.000818  0.897211  0.802389  \n",
       "1  0.026162  0.091577  0.859952  0.001138  0.917975  0.798843  \n",
       "2  0.024511  0.153769  0.859198  0.001045  0.872211  0.843582  \n",
       "3  0.013311  0.227678  0.794469  0.000379  0.869760  0.765059  \n",
       "4  0.014689  0.133337  0.748078  0.000417  0.845494  0.736717  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_normalised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_normalised, labels, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('Speaker_Classification_data/X_train.csv', index=False)\n",
    "X_test.to_csv('Speaker_Classification_data/X_test.csv', index=False)\n",
    "y_train.to_csv('Speaker_Classification_data/y_train.csv', index=False)\n",
    "y_test.to_csv('Speaker_Classification_data/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('SER_data/X_train.csv', index=False)\n",
    "X_test.to_csv('SER_data/X_test.csv', index=False)\n",
    "y_train.to_csv('SER_data/y_train.csv', index=False)\n",
    "y_test.to_csv('SER_data/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_normalised, actor_labels, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./SER_data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"./SER_data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"./SER_data/y_train.csv\")\n",
    "y_test = pd.read_csv(\"./SER_data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train_array = X_train.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "y_train_array = y_train.to_numpy()\n",
    "y_test_array = y_test.to_numpy()\n",
    "lb = LabelEncoder()\n",
    "y_train_cnn = np_utils.to_categorical(lb.fit_transform(y_train_array))\n",
    "y_test_cnn = np_utils.to_categorical(lb.fit_transform(y_test_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y_train_cnn = encoder.fit_transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "Y_test_cnn = encoder.fit_transform(np.array(y_test).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class time_for_batch(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times=[]\n",
    "    def on_train_batch_begin(self, batch, logs={}):\n",
    "        self.starttime = time.time()\n",
    "    def on_train_batch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time()-self.starttime)\n",
    "        \n",
    "class time_for_epoch(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold_cross_validation(no_folds,no_epochs,batch_size,X_train,y_train,X_test,y_test,epoch_times_dict):\n",
    "  hidden_neurons = 16\n",
    "  \n",
    "  print(\"Model training for:\")\n",
    "  print(\"Number of neurons\",hidden_neurons)\n",
    "  print(\"Number of epcohs:\" ,no_epochs)\n",
    "  print(\"No folds used for k-fold cross validation:\", no_folds)\n",
    "  print(\"\")\n",
    "\n",
    "  kf = KFold(n_splits=no_folds,random_state=None, shuffle=False)\n",
    "  KFold(n_splits=no_folds, random_state=None, shuffle=False)\n",
    "  history_results = []\n",
    "  # for train_index, test_index in kf.split(X_train):\n",
    "  # X_train_K, X_test_K = X[train_index], X[test_index]\n",
    "  # y_train_K, y_test_K = Y[train_index], Y[test_index]\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(32, activation='relu'))\n",
    "  # model.add(Dropout(0.3))\n",
    "  model.add(Dense(24, activation='relu'))\n",
    "  # model.add(Dropout(0.3))\n",
    "  model.add(Dense(16, activation='relu'))\n",
    "  # model.add(Dropout(0.3))\n",
    "  model.add(Dense(16, activation='relu'))\n",
    "  model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  tb = time_for_batch()\n",
    "  te = time_for_epoch()\n",
    "\n",
    "  history = model.fit(X_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=no_epochs,\n",
    "                      verbose=2,\n",
    "                      use_multiprocessing=False,\n",
    "                      callbacks = [tb, te],\n",
    "                      validation_data=(X_test, y_test))\n",
    "  epoch_times_dict[hidden_neurons] = te.times\n",
    "  print(\"\")\n",
    "  history_results.append(history)\n",
    "  return history_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training for:\n",
      "Number of neurons 16\n",
      "Number of epcohs: 100\n",
      "No folds used for k-fold cross validation: 3\n",
      "\n",
      "Epoch 1/100\n",
      "504/504 - 1s - loss: 2.0630 - accuracy: 0.1351 - val_loss: 1.9898 - val_accuracy: 0.1574\n",
      "Epoch 2/100\n",
      "504/504 - 0s - loss: 1.9453 - accuracy: 0.2095 - val_loss: 1.9376 - val_accuracy: 0.1736\n",
      "Epoch 3/100\n",
      "504/504 - 0s - loss: 1.8503 - accuracy: 0.2572 - val_loss: 1.7509 - val_accuracy: 0.2940\n",
      "Epoch 4/100\n",
      "504/504 - 1s - loss: 1.7929 - accuracy: 0.2602 - val_loss: 1.7692 - val_accuracy: 0.2963\n",
      "Epoch 5/100\n",
      "504/504 - 1s - loss: 1.7493 - accuracy: 0.2790 - val_loss: 1.6696 - val_accuracy: 0.3287\n",
      "Epoch 6/100\n",
      "504/504 - 1s - loss: 1.7435 - accuracy: 0.2701 - val_loss: 1.7001 - val_accuracy: 0.3403\n",
      "Epoch 7/100\n",
      "504/504 - 1s - loss: 1.7424 - accuracy: 0.2860 - val_loss: 1.6677 - val_accuracy: 0.3495\n",
      "Epoch 8/100\n",
      "504/504 - 0s - loss: 1.7206 - accuracy: 0.2939 - val_loss: 1.6574 - val_accuracy: 0.3519\n",
      "Epoch 9/100\n",
      "504/504 - 0s - loss: 1.6954 - accuracy: 0.2920 - val_loss: 1.6639 - val_accuracy: 0.3194\n",
      "Epoch 10/100\n",
      "504/504 - 1s - loss: 1.6839 - accuracy: 0.3059 - val_loss: 1.6386 - val_accuracy: 0.3449\n",
      "Epoch 11/100\n",
      "504/504 - 0s - loss: 1.6747 - accuracy: 0.2920 - val_loss: 1.6192 - val_accuracy: 0.3704\n",
      "Epoch 12/100\n",
      "504/504 - 1s - loss: 1.6520 - accuracy: 0.3237 - val_loss: 1.6235 - val_accuracy: 0.3935\n",
      "Epoch 13/100\n",
      "504/504 - 0s - loss: 1.6339 - accuracy: 0.3247 - val_loss: 1.6706 - val_accuracy: 0.3241\n",
      "Epoch 14/100\n",
      "504/504 - 0s - loss: 1.6325 - accuracy: 0.3267 - val_loss: 1.6173 - val_accuracy: 0.3866\n",
      "Epoch 15/100\n",
      "504/504 - 0s - loss: 1.6218 - accuracy: 0.3575 - val_loss: 1.6041 - val_accuracy: 0.3935\n",
      "Epoch 16/100\n",
      "504/504 - 0s - loss: 1.6066 - accuracy: 0.3505 - val_loss: 1.5582 - val_accuracy: 0.4236\n",
      "Epoch 17/100\n",
      "504/504 - 0s - loss: 1.5783 - accuracy: 0.3704 - val_loss: 1.6415 - val_accuracy: 0.3356\n",
      "Epoch 18/100\n",
      "504/504 - 0s - loss: 1.5620 - accuracy: 0.3724 - val_loss: 1.5906 - val_accuracy: 0.4144\n",
      "Epoch 19/100\n",
      "504/504 - 0s - loss: 1.5564 - accuracy: 0.3704 - val_loss: 1.5423 - val_accuracy: 0.4028\n",
      "Epoch 20/100\n",
      "504/504 - 0s - loss: 1.5273 - accuracy: 0.3942 - val_loss: 1.5287 - val_accuracy: 0.4097\n",
      "Epoch 21/100\n",
      "504/504 - 0s - loss: 1.5277 - accuracy: 0.3893 - val_loss: 1.5175 - val_accuracy: 0.4421\n",
      "Epoch 22/100\n",
      "504/504 - 0s - loss: 1.5095 - accuracy: 0.4081 - val_loss: 1.5237 - val_accuracy: 0.4329\n",
      "Epoch 23/100\n",
      "504/504 - 0s - loss: 1.4958 - accuracy: 0.4181 - val_loss: 1.5318 - val_accuracy: 0.4097\n",
      "Epoch 24/100\n",
      "504/504 - 0s - loss: 1.4872 - accuracy: 0.4300 - val_loss: 1.5540 - val_accuracy: 0.4190\n",
      "Epoch 25/100\n",
      "504/504 - 0s - loss: 1.4820 - accuracy: 0.4191 - val_loss: 1.5516 - val_accuracy: 0.4051\n",
      "Epoch 26/100\n",
      "504/504 - 0s - loss: 1.4631 - accuracy: 0.4201 - val_loss: 1.5125 - val_accuracy: 0.4051\n",
      "Epoch 27/100\n",
      "504/504 - 0s - loss: 1.4549 - accuracy: 0.4260 - val_loss: 1.6285 - val_accuracy: 0.3958\n",
      "Epoch 28/100\n",
      "504/504 - 0s - loss: 1.4527 - accuracy: 0.4300 - val_loss: 1.6344 - val_accuracy: 0.3519\n",
      "Epoch 29/100\n",
      "504/504 - 0s - loss: 1.4367 - accuracy: 0.4459 - val_loss: 1.4978 - val_accuracy: 0.4444\n",
      "Epoch 30/100\n",
      "504/504 - 0s - loss: 1.4349 - accuracy: 0.4340 - val_loss: 1.5141 - val_accuracy: 0.4306\n",
      "Epoch 31/100\n",
      "504/504 - 0s - loss: 1.4158 - accuracy: 0.4369 - val_loss: 1.5082 - val_accuracy: 0.4560\n",
      "Epoch 32/100\n",
      "504/504 - 0s - loss: 1.4093 - accuracy: 0.4459 - val_loss: 1.4960 - val_accuracy: 0.4306\n",
      "Epoch 33/100\n",
      "504/504 - 0s - loss: 1.3961 - accuracy: 0.4578 - val_loss: 1.4834 - val_accuracy: 0.4560\n",
      "Epoch 34/100\n",
      "504/504 - 0s - loss: 1.3918 - accuracy: 0.4578 - val_loss: 1.5362 - val_accuracy: 0.4005\n",
      "Epoch 35/100\n",
      "504/504 - 1s - loss: 1.3864 - accuracy: 0.4489 - val_loss: 1.4983 - val_accuracy: 0.4537\n",
      "Epoch 36/100\n",
      "504/504 - 1s - loss: 1.3750 - accuracy: 0.4479 - val_loss: 1.5618 - val_accuracy: 0.3958\n",
      "Epoch 37/100\n",
      "504/504 - 1s - loss: 1.3643 - accuracy: 0.4518 - val_loss: 1.5892 - val_accuracy: 0.3843\n",
      "Epoch 38/100\n",
      "504/504 - 0s - loss: 1.3582 - accuracy: 0.4628 - val_loss: 1.5058 - val_accuracy: 0.4028\n",
      "Epoch 39/100\n",
      "504/504 - 0s - loss: 1.3411 - accuracy: 0.4657 - val_loss: 1.5612 - val_accuracy: 0.4259\n",
      "Epoch 40/100\n",
      "504/504 - 0s - loss: 1.3521 - accuracy: 0.4598 - val_loss: 1.5233 - val_accuracy: 0.4444\n",
      "Epoch 41/100\n",
      "504/504 - 0s - loss: 1.3372 - accuracy: 0.4667 - val_loss: 1.6282 - val_accuracy: 0.4028\n",
      "Epoch 42/100\n",
      "504/504 - 0s - loss: 1.3175 - accuracy: 0.4777 - val_loss: 1.5320 - val_accuracy: 0.4259\n",
      "Epoch 43/100\n",
      "504/504 - 0s - loss: 1.3208 - accuracy: 0.4727 - val_loss: 1.4709 - val_accuracy: 0.4375\n",
      "Epoch 44/100\n",
      "504/504 - 0s - loss: 1.3004 - accuracy: 0.4896 - val_loss: 1.5269 - val_accuracy: 0.4190\n",
      "Epoch 45/100\n",
      "504/504 - 0s - loss: 1.3043 - accuracy: 0.4707 - val_loss: 1.4765 - val_accuracy: 0.4653\n",
      "Epoch 46/100\n",
      "504/504 - 0s - loss: 1.2939 - accuracy: 0.4896 - val_loss: 1.5102 - val_accuracy: 0.4444\n",
      "Epoch 47/100\n",
      "504/504 - 0s - loss: 1.2802 - accuracy: 0.4935 - val_loss: 1.5596 - val_accuracy: 0.4306\n",
      "Epoch 48/100\n",
      "504/504 - 0s - loss: 1.2718 - accuracy: 0.5015 - val_loss: 1.4831 - val_accuracy: 0.4421\n",
      "Epoch 49/100\n",
      "504/504 - 0s - loss: 1.2644 - accuracy: 0.4896 - val_loss: 1.5862 - val_accuracy: 0.4051\n",
      "Epoch 50/100\n",
      "504/504 - 0s - loss: 1.2544 - accuracy: 0.4995 - val_loss: 1.5194 - val_accuracy: 0.4259\n",
      "Epoch 51/100\n",
      "504/504 - 1s - loss: 1.2658 - accuracy: 0.5015 - val_loss: 1.4885 - val_accuracy: 0.4329\n",
      "Epoch 52/100\n",
      "504/504 - 1s - loss: 1.2325 - accuracy: 0.4985 - val_loss: 1.5448 - val_accuracy: 0.4097\n",
      "Epoch 53/100\n",
      "504/504 - 0s - loss: 1.2420 - accuracy: 0.5223 - val_loss: 1.4604 - val_accuracy: 0.4745\n",
      "Epoch 54/100\n",
      "504/504 - 1s - loss: 1.2068 - accuracy: 0.5343 - val_loss: 1.4621 - val_accuracy: 0.4560\n",
      "Epoch 55/100\n",
      "504/504 - 1s - loss: 1.1760 - accuracy: 0.5402 - val_loss: 1.5007 - val_accuracy: 0.4375\n",
      "Epoch 56/100\n",
      "504/504 - 1s - loss: 1.2075 - accuracy: 0.5055 - val_loss: 1.4798 - val_accuracy: 0.4491\n",
      "Epoch 57/100\n",
      "504/504 - 0s - loss: 1.1965 - accuracy: 0.5333 - val_loss: 1.5679 - val_accuracy: 0.4097\n",
      "Epoch 58/100\n",
      "504/504 - 0s - loss: 1.1744 - accuracy: 0.5362 - val_loss: 1.5748 - val_accuracy: 0.4769\n",
      "Epoch 59/100\n",
      "504/504 - 0s - loss: 1.1966 - accuracy: 0.5372 - val_loss: 1.5393 - val_accuracy: 0.4259\n",
      "Epoch 60/100\n",
      "504/504 - 0s - loss: 1.1869 - accuracy: 0.5353 - val_loss: 1.4398 - val_accuracy: 0.4699\n",
      "Epoch 61/100\n",
      "504/504 - 0s - loss: 1.1776 - accuracy: 0.5283 - val_loss: 1.5037 - val_accuracy: 0.4722\n",
      "Epoch 62/100\n",
      "504/504 - 1s - loss: 1.1569 - accuracy: 0.5472 - val_loss: 1.4599 - val_accuracy: 0.4537\n",
      "Epoch 63/100\n",
      "504/504 - 1s - loss: 1.1284 - accuracy: 0.5670 - val_loss: 1.5650 - val_accuracy: 0.4028\n",
      "Epoch 64/100\n",
      "504/504 - 0s - loss: 1.1547 - accuracy: 0.5601 - val_loss: 1.4853 - val_accuracy: 0.4074\n",
      "Epoch 65/100\n",
      "504/504 - 0s - loss: 1.1554 - accuracy: 0.5551 - val_loss: 1.5311 - val_accuracy: 0.4491\n",
      "Epoch 66/100\n",
      "504/504 - 1s - loss: 1.1382 - accuracy: 0.5641 - val_loss: 1.4856 - val_accuracy: 0.4583\n",
      "Epoch 67/100\n",
      "504/504 - 0s - loss: 1.1086 - accuracy: 0.5581 - val_loss: 1.4997 - val_accuracy: 0.4491\n",
      "Epoch 68/100\n",
      "504/504 - 0s - loss: 1.1259 - accuracy: 0.5750 - val_loss: 1.4950 - val_accuracy: 0.4560\n",
      "Epoch 69/100\n",
      "504/504 - 0s - loss: 1.0962 - accuracy: 0.5710 - val_loss: 1.5090 - val_accuracy: 0.4097\n",
      "Epoch 70/100\n",
      "504/504 - 0s - loss: 1.1017 - accuracy: 0.5680 - val_loss: 1.6507 - val_accuracy: 0.4398\n",
      "Epoch 71/100\n",
      "504/504 - 1s - loss: 1.1175 - accuracy: 0.5690 - val_loss: 1.5627 - val_accuracy: 0.4398\n",
      "Epoch 72/100\n",
      "504/504 - 0s - loss: 1.1034 - accuracy: 0.5700 - val_loss: 1.4942 - val_accuracy: 0.4745\n",
      "Epoch 73/100\n",
      "504/504 - 0s - loss: 1.0916 - accuracy: 0.5829 - val_loss: 1.4287 - val_accuracy: 0.4676\n",
      "Epoch 74/100\n",
      "504/504 - 0s - loss: 1.0518 - accuracy: 0.6107 - val_loss: 1.7841 - val_accuracy: 0.4097\n",
      "Epoch 75/100\n",
      "504/504 - 0s - loss: 1.0689 - accuracy: 0.5839 - val_loss: 1.4836 - val_accuracy: 0.4514\n",
      "Epoch 76/100\n",
      "504/504 - 0s - loss: 1.0530 - accuracy: 0.5988 - val_loss: 1.5164 - val_accuracy: 0.4537\n",
      "Epoch 77/100\n",
      "504/504 - 0s - loss: 1.0703 - accuracy: 0.5988 - val_loss: 1.5726 - val_accuracy: 0.4815\n",
      "Epoch 78/100\n",
      "504/504 - 1s - loss: 1.0480 - accuracy: 0.5919 - val_loss: 1.4915 - val_accuracy: 0.4722\n",
      "Epoch 79/100\n",
      "504/504 - 0s - loss: 1.0401 - accuracy: 0.6008 - val_loss: 1.4745 - val_accuracy: 0.4769\n",
      "Epoch 80/100\n",
      "504/504 - 1s - loss: 1.0658 - accuracy: 0.5948 - val_loss: 1.7189 - val_accuracy: 0.4213\n",
      "Epoch 81/100\n",
      "504/504 - 1s - loss: 1.0070 - accuracy: 0.6137 - val_loss: 1.6192 - val_accuracy: 0.4861\n",
      "Epoch 82/100\n",
      "504/504 - 0s - loss: 1.0479 - accuracy: 0.5948 - val_loss: 1.5055 - val_accuracy: 0.4653\n",
      "Epoch 83/100\n",
      "504/504 - 0s - loss: 1.0196 - accuracy: 0.6216 - val_loss: 1.4791 - val_accuracy: 0.4699\n",
      "Epoch 84/100\n",
      "504/504 - 0s - loss: 1.0029 - accuracy: 0.6117 - val_loss: 1.5301 - val_accuracy: 0.4051\n",
      "Epoch 85/100\n",
      "504/504 - 0s - loss: 1.0337 - accuracy: 0.5998 - val_loss: 1.6151 - val_accuracy: 0.4722\n",
      "Epoch 86/100\n",
      "504/504 - 0s - loss: 1.0021 - accuracy: 0.6197 - val_loss: 1.5583 - val_accuracy: 0.4815\n",
      "Epoch 87/100\n",
      "504/504 - 0s - loss: 1.0221 - accuracy: 0.6097 - val_loss: 1.5759 - val_accuracy: 0.4606\n",
      "Epoch 88/100\n",
      "504/504 - 0s - loss: 0.9816 - accuracy: 0.6226 - val_loss: 1.5299 - val_accuracy: 0.4491\n",
      "Epoch 89/100\n",
      "504/504 - 1s - loss: 0.9808 - accuracy: 0.6207 - val_loss: 1.5953 - val_accuracy: 0.4259\n",
      "Epoch 90/100\n",
      "504/504 - 1s - loss: 0.9590 - accuracy: 0.6395 - val_loss: 1.5352 - val_accuracy: 0.4861\n",
      "Epoch 91/100\n",
      "504/504 - 0s - loss: 0.9610 - accuracy: 0.6137 - val_loss: 1.6124 - val_accuracy: 0.4190\n",
      "Epoch 92/100\n",
      "504/504 - 0s - loss: 0.9579 - accuracy: 0.6326 - val_loss: 1.4617 - val_accuracy: 0.4745\n",
      "Epoch 93/100\n",
      "504/504 - 1s - loss: 0.9566 - accuracy: 0.6197 - val_loss: 1.4876 - val_accuracy: 0.4583\n",
      "Epoch 94/100\n",
      "504/504 - 1s - loss: 0.9487 - accuracy: 0.6346 - val_loss: 1.4615 - val_accuracy: 0.4861\n",
      "Epoch 95/100\n",
      "504/504 - 1s - loss: 0.9355 - accuracy: 0.6465 - val_loss: 2.0663 - val_accuracy: 0.3935\n",
      "Epoch 96/100\n",
      "504/504 - 1s - loss: 0.9446 - accuracy: 0.6375 - val_loss: 1.6058 - val_accuracy: 0.4421\n",
      "Epoch 97/100\n",
      "504/504 - 0s - loss: 0.9068 - accuracy: 0.6574 - val_loss: 1.5678 - val_accuracy: 0.4653\n",
      "Epoch 98/100\n",
      "504/504 - 1s - loss: 0.9507 - accuracy: 0.6346 - val_loss: 1.5530 - val_accuracy: 0.4375\n",
      "Epoch 99/100\n",
      "504/504 - 1s - loss: 0.9039 - accuracy: 0.6554 - val_loss: 1.6945 - val_accuracy: 0.4606\n",
      "Epoch 100/100\n",
      "504/504 - 0s - loss: 0.8994 - accuracy: 0.6663 - val_loss: 1.5910 - val_accuracy: 0.4653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Batch_sizes = [2]\n",
    "model_results = {}\n",
    "epoch_times_dict = {}\n",
    "for size in Batch_sizes:\n",
    "  history = K_fold_cross_validation(3,100,size,X_train_array,y_train_array-1,X_test_array,y_test_array-1,epoch_times_dict)\n",
    "  model_results[size] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = pd.read_csv(\"./SER_data/X_train.csv\")\n",
    "x_test_new = pd.read_csv(\"./SER_data/X_test.csv\")\n",
    "y_train_new = pd.read_csv(\"./SER_data/y_train.csv\")\n",
    "y_test_new = pd.read_csv(\"./SER_data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [x_train_new, x_test_new]\n",
    "result_train = pd.concat(frames)\n",
    "frames = [y_train_new, y_test_new]\n",
    "results_test = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_layers(no_folds,no_epochs,batch_size,X_train,y_train,X_test,y_test,epoch_times_dict):  \n",
    "  hidden_neurons = 16\n",
    "  print(\"Model training for:\")\n",
    "  print(\"Number of neurons\",hidden_neurons)\n",
    "  print(\"Number of epcohs:\" ,no_epochs)\n",
    "  print(\"No folds used for k-fold cross validation:\", no_folds)\n",
    "  print(\"\")\n",
    "\n",
    "  kf = KFold(n_splits=no_folds,random_state=None, shuffle=False)\n",
    "  KFold(n_splits=no_folds, random_state=None, shuffle=False)\n",
    "  history_results = []\n",
    "#   for train_index, test_index in kf.split(X_train):\n",
    "#         X_train_K, X_test_K = X_train[train_index], X_train[test_index]\n",
    "#         y_train_K, y_test_K = y_train[train_index], y_train[test_index]\n",
    "  model_cnn = Sequential()\n",
    "  model_cnn.add(Conv1D(64,kernel_size=5,strides=1,activation='relu',input_shape=(X_train.shape[1],1)))\n",
    "  model_cnn.add(BatchNormalization())\n",
    "  # model_cnn.add(Conv1D(64,kernel_size=5,strides=1,activation='relu'))\n",
    "  # model_cnn.add(Dropout(0.1))\n",
    "  # model_cnn.add(BatchNormalization())\n",
    "  # model_cnn.add(MaxPooling1D(pool_size=8,strides=2))\n",
    "  model_cnn.add(Conv1D(32,kernel_size=5,activation='relu'))\n",
    "  # model_cnn.add(Conv1D(32,kernel_size=5,activation='relu'))\n",
    "  # model_cnn.add(Conv1D(32,kernel_size=5))\n",
    "  model_cnn.add(BatchNormalization())\n",
    "  model_cnn.add(Dropout(0.2))\n",
    "  model_cnn.add(Flatten())\n",
    "  # model_cnn.add(Dense(16))\n",
    "  # model_cnn.add(Dropout(0.2))\n",
    "  model_cnn.add(Dense(8))\n",
    "  model_cnn.compile(optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "  print(model_cnn.summary())\n",
    "\n",
    "  history = model.fit(X_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=no_epochs,\n",
    "                verbose=2,\n",
    "                use_multiprocessing=False,\n",
    "                callbacks = [tb, te],\n",
    "                validation_data=(X_test, y_test))\n",
    "\n",
    "  epoch_times_dict[hidden_neurons] = te.times\n",
    "  print(\"\")\n",
    "  history_results.append(history)\n",
    "  return history_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn_new = np.expand_dims(x_train_new, axis=2)\n",
    "y_train_cnn_new = encoder.fit_transform(np.array(y_train_new).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training for:\n",
      "Number of neurons 16\n",
      "Number of epcohs: 100\n",
      "No folds used for k-fold cross validation: 2\n",
      "\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_85 (Conv1D)           (None, 43, 64)            384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 43, 64)            256       \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 39, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 39, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 39, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 1248)              0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 8)                 9992      \n",
      "=================================================================\n",
      "Total params: 21,032\n",
      "Trainable params: 20,840\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1007/1007 - 3s - loss: 0.2047 - accuracy: 0.9484 - val_loss: 5.7960 - val_accuracy: 0.4537\n",
      "Epoch 2/100\n",
      "1007/1007 - 3s - loss: 0.2115 - accuracy: 0.9424 - val_loss: 5.9997 - val_accuracy: 0.4468\n",
      "Epoch 3/100\n",
      "1007/1007 - 3s - loss: 0.2277 - accuracy: 0.9513 - val_loss: 6.0226 - val_accuracy: 0.4537\n",
      "Epoch 4/100\n",
      "1007/1007 - 3s - loss: 0.1321 - accuracy: 0.9682 - val_loss: 6.5679 - val_accuracy: 0.4606\n",
      "Epoch 5/100\n",
      "1007/1007 - 3s - loss: 0.4253 - accuracy: 0.8997 - val_loss: 6.4162 - val_accuracy: 0.4236\n",
      "Epoch 6/100\n",
      "1007/1007 - 3s - loss: 0.3191 - accuracy: 0.9325 - val_loss: 6.1134 - val_accuracy: 0.4931\n",
      "Epoch 7/100\n",
      "1007/1007 - 3s - loss: 0.2584 - accuracy: 0.9364 - val_loss: 5.6776 - val_accuracy: 0.4282\n",
      "Epoch 8/100\n",
      "1007/1007 - 4s - loss: 0.1505 - accuracy: 0.9573 - val_loss: 6.8531 - val_accuracy: 0.4653\n",
      "Epoch 9/100\n",
      "1007/1007 - 4s - loss: 0.3357 - accuracy: 0.9335 - val_loss: 5.2852 - val_accuracy: 0.4282\n",
      "Epoch 10/100\n",
      "1007/1007 - 4s - loss: 0.2434 - accuracy: 0.9325 - val_loss: 7.4504 - val_accuracy: 0.4375\n",
      "Epoch 11/100\n",
      "1007/1007 - 3s - loss: 0.1768 - accuracy: 0.9603 - val_loss: 6.1316 - val_accuracy: 0.4722\n",
      "Epoch 12/100\n",
      "1007/1007 - 3s - loss: 0.3541 - accuracy: 0.9315 - val_loss: 5.4419 - val_accuracy: 0.4213\n",
      "Epoch 13/100\n",
      "1007/1007 - 3s - loss: 0.1706 - accuracy: 0.9434 - val_loss: 6.5290 - val_accuracy: 0.4282\n",
      "Epoch 14/100\n",
      "1007/1007 - 3s - loss: 0.1485 - accuracy: 0.9722 - val_loss: 7.1509 - val_accuracy: 0.4537\n",
      "Epoch 15/100\n",
      "1007/1007 - 3s - loss: 0.4924 - accuracy: 0.8868 - val_loss: 5.4196 - val_accuracy: 0.4653\n",
      "Epoch 16/100\n",
      "1007/1007 - 3s - loss: 0.1852 - accuracy: 0.9434 - val_loss: 7.2220 - val_accuracy: 0.4491\n",
      "Epoch 17/100\n",
      "1007/1007 - 3s - loss: 0.3018 - accuracy: 0.9355 - val_loss: 6.3953 - val_accuracy: 0.4606\n",
      "Epoch 18/100\n",
      "1007/1007 - 4s - loss: 0.1790 - accuracy: 0.9513 - val_loss: 7.5216 - val_accuracy: 0.4560\n",
      "Epoch 19/100\n",
      "1007/1007 - 4s - loss: 0.3638 - accuracy: 0.9166 - val_loss: 6.0087 - val_accuracy: 0.4514\n",
      "Epoch 20/100\n",
      "1007/1007 - 4s - loss: 0.2710 - accuracy: 0.9364 - val_loss: 5.7676 - val_accuracy: 0.4537\n",
      "Epoch 21/100\n",
      "1007/1007 - 4s - loss: 0.1922 - accuracy: 0.9434 - val_loss: 6.1082 - val_accuracy: 0.4306\n",
      "Epoch 22/100\n",
      "1007/1007 - 4s - loss: 0.2456 - accuracy: 0.9355 - val_loss: 6.6167 - val_accuracy: 0.4468\n",
      "Epoch 23/100\n",
      "1007/1007 - 4s - loss: 0.2553 - accuracy: 0.9345 - val_loss: 6.3473 - val_accuracy: 0.4514\n",
      "Epoch 24/100\n",
      "1007/1007 - 3s - loss: 0.0794 - accuracy: 0.9772 - val_loss: 7.8793 - val_accuracy: 0.4676\n",
      "Epoch 25/100\n",
      "1007/1007 - 3s - loss: 0.3635 - accuracy: 0.9295 - val_loss: 6.7513 - val_accuracy: 0.4838\n",
      "Epoch 26/100\n",
      "1007/1007 - 3s - loss: 0.2974 - accuracy: 0.9454 - val_loss: 6.0412 - val_accuracy: 0.4606\n",
      "Epoch 27/100\n",
      "1007/1007 - 5s - loss: 0.1511 - accuracy: 0.9563 - val_loss: 7.8048 - val_accuracy: 0.4676\n",
      "Epoch 28/100\n",
      "1007/1007 - 4s - loss: 0.2577 - accuracy: 0.9394 - val_loss: 7.4140 - val_accuracy: 0.4421\n",
      "Epoch 29/100\n",
      "1007/1007 - 4s - loss: 0.3842 - accuracy: 0.9295 - val_loss: 5.8751 - val_accuracy: 0.4468\n",
      "Epoch 30/100\n",
      "1007/1007 - 3s - loss: 0.1031 - accuracy: 0.9742 - val_loss: 5.9140 - val_accuracy: 0.4514\n",
      "Epoch 31/100\n",
      "1007/1007 - 3s - loss: 0.4648 - accuracy: 0.9126 - val_loss: 5.6703 - val_accuracy: 0.4815\n",
      "Epoch 32/100\n",
      "1007/1007 - 3s - loss: 0.3312 - accuracy: 0.9146 - val_loss: 5.6675 - val_accuracy: 0.4676\n",
      "Epoch 33/100\n",
      "1007/1007 - 3s - loss: 0.2826 - accuracy: 0.9484 - val_loss: 6.4103 - val_accuracy: 0.4861\n",
      "Epoch 34/100\n",
      "1007/1007 - 3s - loss: 0.0877 - accuracy: 0.9692 - val_loss: 6.0503 - val_accuracy: 0.4676\n",
      "Epoch 35/100\n",
      "1007/1007 - 3s - loss: 0.2660 - accuracy: 0.9494 - val_loss: 6.7096 - val_accuracy: 0.4259\n",
      "Epoch 36/100\n",
      "1007/1007 - 3s - loss: 0.3132 - accuracy: 0.9295 - val_loss: 7.1528 - val_accuracy: 0.4699\n",
      "Epoch 37/100\n",
      "1007/1007 - 3s - loss: 0.1643 - accuracy: 0.9563 - val_loss: 6.8241 - val_accuracy: 0.4630\n",
      "Epoch 38/100\n",
      "1007/1007 - 3s - loss: 0.5035 - accuracy: 0.9076 - val_loss: 5.1758 - val_accuracy: 0.4468\n",
      "Epoch 39/100\n",
      "1007/1007 - 175s - loss: 0.4284 - accuracy: 0.8928 - val_loss: 5.5714 - val_accuracy: 0.4560\n",
      "Epoch 40/100\n",
      "1007/1007 - 4s - loss: 0.1120 - accuracy: 0.9633 - val_loss: 6.1443 - val_accuracy: 0.4838\n",
      "Epoch 41/100\n",
      "1007/1007 - 4s - loss: 0.1171 - accuracy: 0.9603 - val_loss: 6.7191 - val_accuracy: 0.4606\n",
      "Epoch 42/100\n",
      "1007/1007 - 89s - loss: 0.3201 - accuracy: 0.9345 - val_loss: 5.9125 - val_accuracy: 0.4606\n",
      "Epoch 43/100\n",
      "1007/1007 - 5s - loss: 0.3774 - accuracy: 0.9305 - val_loss: 6.0191 - val_accuracy: 0.4537\n",
      "Epoch 44/100\n",
      "1007/1007 - 3s - loss: 0.1826 - accuracy: 0.9563 - val_loss: 5.7141 - val_accuracy: 0.4722\n",
      "Epoch 45/100\n",
      "1007/1007 - 48s - loss: 0.2422 - accuracy: 0.9444 - val_loss: 7.1917 - val_accuracy: 0.4630\n",
      "Epoch 46/100\n",
      "1007/1007 - 4s - loss: 0.3220 - accuracy: 0.9225 - val_loss: 8.1445 - val_accuracy: 0.4329\n",
      "Epoch 47/100\n",
      "1007/1007 - 4s - loss: 0.1662 - accuracy: 0.9434 - val_loss: 5.6463 - val_accuracy: 0.4514\n",
      "Epoch 48/100\n",
      "1007/1007 - 33s - loss: 0.2167 - accuracy: 0.9325 - val_loss: 6.3058 - val_accuracy: 0.4560\n",
      "Epoch 49/100\n",
      "1007/1007 - 4s - loss: 0.2389 - accuracy: 0.9503 - val_loss: 6.2247 - val_accuracy: 0.4861\n",
      "Epoch 50/100\n",
      "1007/1007 - 5s - loss: 0.2620 - accuracy: 0.9464 - val_loss: 6.4331 - val_accuracy: 0.4560\n",
      "Epoch 51/100\n",
      "1007/1007 - 22s - loss: 0.2549 - accuracy: 0.9464 - val_loss: 4.6580 - val_accuracy: 0.4375\n",
      "Epoch 52/100\n",
      "1007/1007 - 24s - loss: 0.2653 - accuracy: 0.9335 - val_loss: 7.4832 - val_accuracy: 0.4630\n",
      "Epoch 53/100\n",
      "1007/1007 - 5s - loss: 0.2835 - accuracy: 0.9424 - val_loss: 5.8239 - val_accuracy: 0.4236\n",
      "Epoch 54/100\n",
      "1007/1007 - 12s - loss: 0.2022 - accuracy: 0.9434 - val_loss: 6.6894 - val_accuracy: 0.4352\n",
      "Epoch 55/100\n",
      "1007/1007 - 884s - loss: 0.1724 - accuracy: 0.9623 - val_loss: 7.7078 - val_accuracy: 0.4398\n",
      "Epoch 56/100\n",
      "1007/1007 - 4s - loss: 0.7867 - accuracy: 0.8838 - val_loss: 5.2393 - val_accuracy: 0.4375\n",
      "Epoch 57/100\n",
      "1007/1007 - 3s - loss: 0.1490 - accuracy: 0.9593 - val_loss: 6.9413 - val_accuracy: 0.4491\n",
      "Epoch 58/100\n",
      "1007/1007 - 894s - loss: 0.2454 - accuracy: 0.9474 - val_loss: 6.1576 - val_accuracy: 0.4329\n",
      "Epoch 59/100\n",
      "1007/1007 - 3s - loss: 0.2095 - accuracy: 0.9563 - val_loss: 6.6299 - val_accuracy: 0.3981\n",
      "Epoch 60/100\n",
      "1007/1007 - 3s - loss: 0.3986 - accuracy: 0.9146 - val_loss: 5.9970 - val_accuracy: 0.4722\n",
      "Epoch 61/100\n",
      "1007/1007 - 4s - loss: 0.2833 - accuracy: 0.9325 - val_loss: 6.8428 - val_accuracy: 0.4583\n",
      "Epoch 62/100\n",
      "1007/1007 - 2722s - loss: 0.3361 - accuracy: 0.9265 - val_loss: 5.1580 - val_accuracy: 0.4606\n",
      "Epoch 63/100\n",
      "1007/1007 - 4s - loss: 0.0985 - accuracy: 0.9712 - val_loss: 6.2818 - val_accuracy: 0.4468\n",
      "Epoch 64/100\n",
      "1007/1007 - 3s - loss: 0.0993 - accuracy: 0.9712 - val_loss: 6.9890 - val_accuracy: 0.4838\n",
      "Epoch 65/100\n",
      "1007/1007 - 763s - loss: 0.2645 - accuracy: 0.9345 - val_loss: 5.9588 - val_accuracy: 0.4583\n",
      "Epoch 66/100\n",
      "1007/1007 - 4s - loss: 0.4176 - accuracy: 0.9255 - val_loss: 6.7855 - val_accuracy: 0.4606\n",
      "Epoch 67/100\n",
      "1007/1007 - 3s - loss: 0.2715 - accuracy: 0.9295 - val_loss: 6.2280 - val_accuracy: 0.4653\n",
      "Epoch 68/100\n",
      "1007/1007 - 3s - loss: 0.1732 - accuracy: 0.9583 - val_loss: 6.1311 - val_accuracy: 0.4630\n",
      "Epoch 69/100\n",
      "1007/1007 - 26s - loss: 0.1843 - accuracy: 0.9543 - val_loss: 8.5540 - val_accuracy: 0.4329\n",
      "Epoch 70/100\n",
      "1007/1007 - 3s - loss: 0.2264 - accuracy: 0.9603 - val_loss: 7.0899 - val_accuracy: 0.4190\n",
      "Epoch 71/100\n",
      "1007/1007 - 3s - loss: 0.6336 - accuracy: 0.8928 - val_loss: 6.1768 - val_accuracy: 0.3819\n",
      "Epoch 72/100\n",
      "1007/1007 - 3s - loss: 0.3897 - accuracy: 0.9037 - val_loss: 4.9477 - val_accuracy: 0.4514\n",
      "Epoch 73/100\n",
      "1007/1007 - 1904s - loss: 0.0894 - accuracy: 0.9712 - val_loss: 6.8541 - val_accuracy: 0.4259\n",
      "Epoch 74/100\n",
      "1007/1007 - 4s - loss: 0.0791 - accuracy: 0.9811 - val_loss: 8.2818 - val_accuracy: 0.4583\n",
      "Epoch 75/100\n",
      "1007/1007 - 3s - loss: 0.7321 - accuracy: 0.8699 - val_loss: 6.5782 - val_accuracy: 0.4375\n",
      "Epoch 76/100\n",
      "1007/1007 - 3s - loss: 0.1834 - accuracy: 0.9613 - val_loss: 7.9552 - val_accuracy: 0.4144\n",
      "Epoch 77/100\n",
      "1007/1007 - 3s - loss: 0.3983 - accuracy: 0.9196 - val_loss: 4.6973 - val_accuracy: 0.4120\n",
      "Epoch 78/100\n",
      "1007/1007 - 3s - loss: 0.2110 - accuracy: 0.9464 - val_loss: 6.5558 - val_accuracy: 0.4792\n",
      "Epoch 79/100\n",
      "1007/1007 - 5s - loss: 0.3435 - accuracy: 0.9285 - val_loss: 7.0233 - val_accuracy: 0.4213\n",
      "Epoch 80/100\n",
      "1007/1007 - 4s - loss: 0.4396 - accuracy: 0.9086 - val_loss: 7.0552 - val_accuracy: 0.4306\n",
      "Epoch 81/100\n",
      "1007/1007 - 3s - loss: 0.1539 - accuracy: 0.9593 - val_loss: 5.2651 - val_accuracy: 0.4468\n",
      "Epoch 82/100\n",
      "1007/1007 - 3s - loss: 0.1361 - accuracy: 0.9643 - val_loss: 7.5509 - val_accuracy: 0.4583\n",
      "Epoch 83/100\n",
      "1007/1007 - 3s - loss: 0.2486 - accuracy: 0.9484 - val_loss: 6.4113 - val_accuracy: 0.4722\n",
      "Epoch 84/100\n",
      "1007/1007 - 3s - loss: 0.2543 - accuracy: 0.9335 - val_loss: 6.0874 - val_accuracy: 0.4375\n",
      "Epoch 85/100\n",
      "1007/1007 - 13s - loss: 0.1039 - accuracy: 0.9732 - val_loss: 6.4316 - val_accuracy: 0.4676\n",
      "Epoch 86/100\n",
      "1007/1007 - 19s - loss: 0.1505 - accuracy: 0.9712 - val_loss: 5.9567 - val_accuracy: 0.4745\n",
      "Epoch 87/100\n",
      "1007/1007 - 21s - loss: 0.3827 - accuracy: 0.9295 - val_loss: 6.2876 - val_accuracy: 0.4167\n",
      "Epoch 88/100\n",
      "1007/1007 - 24s - loss: 0.3319 - accuracy: 0.9295 - val_loss: 6.7609 - val_accuracy: 0.4537\n",
      "Epoch 89/100\n",
      "1007/1007 - 4s - loss: 0.2533 - accuracy: 0.9484 - val_loss: 6.1577 - val_accuracy: 0.4653\n",
      "Epoch 90/100\n",
      "1007/1007 - 4s - loss: 0.2195 - accuracy: 0.9613 - val_loss: 7.1015 - val_accuracy: 0.4583\n",
      "Epoch 91/100\n",
      "1007/1007 - 3s - loss: 0.3658 - accuracy: 0.9245 - val_loss: 6.4513 - val_accuracy: 0.4236\n",
      "Epoch 92/100\n",
      "1007/1007 - 3s - loss: 0.1206 - accuracy: 0.9702 - val_loss: 7.2000 - val_accuracy: 0.4699\n",
      "Epoch 93/100\n",
      "1007/1007 - 3s - loss: 0.2525 - accuracy: 0.9374 - val_loss: 6.4376 - val_accuracy: 0.4491\n",
      "Epoch 94/100\n",
      "1007/1007 - 3s - loss: 0.3404 - accuracy: 0.9394 - val_loss: 6.8387 - val_accuracy: 0.4005\n",
      "Epoch 95/100\n",
      "1007/1007 - 3s - loss: 0.2545 - accuracy: 0.9523 - val_loss: 5.6612 - val_accuracy: 0.4792\n",
      "Epoch 96/100\n",
      "1007/1007 - 3s - loss: 0.2358 - accuracy: 0.9573 - val_loss: 6.9683 - val_accuracy: 0.4491\n",
      "Epoch 97/100\n",
      "1007/1007 - 3s - loss: 0.1828 - accuracy: 0.9593 - val_loss: 7.0049 - val_accuracy: 0.4769\n",
      "Epoch 98/100\n",
      "1007/1007 - 3s - loss: 0.2338 - accuracy: 0.9454 - val_loss: 7.6078 - val_accuracy: 0.4398\n",
      "Epoch 99/100\n",
      "1007/1007 - 3s - loss: 0.1557 - accuracy: 0.9583 - val_loss: 7.9425 - val_accuracy: 0.4676\n",
      "Epoch 100/100\n",
      "1007/1007 - 3s - loss: 0.5874 - accuracy: 0.8977 - val_loss: 5.0547 - val_accuracy: 0.4236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Batch_sizes = [1]\n",
    "model_results = {}\n",
    "epoch_times_dict = {}\n",
    "for size in Batch_sizes:\n",
    "  history = cnn_layers(2,100,size,X_train_cnn,Y_train_cnn,X_test_cnn,Y_test_cnn,epoch_times_dict)\n",
    "  model_results[size] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 47, 256)           1536      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 24, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 12, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 12, 128)           163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 6, 64)             41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 32)                6176      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 540,904\n",
      "Trainable params: 540,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(X_train_cnn.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=8, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_44 (Conv1D)           (None, 43, 64)            384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 43, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 43, 64)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 43, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 18, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 14, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 32)                14368     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 25,928\n",
      "Trainable params: 25,608\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(64,kernel_size=5,strides=1,activation='relu',input_shape=(X_train_cnn.shape[1],1)))\n",
    "model_cnn.add(BatchNormalization())\n",
    "# model_cnn.add(Conv1D(64,kernel_size=5,strides=1,activation='relu'))\n",
    "model_cnn.add(Dropout(0.1))\n",
    "model_cnn.add(BatchNormalization())\n",
    "model_cnn.add(MaxPooling1D(pool_size=8,strides=2))\n",
    "model_cnn.add(Conv1D(32,kernel_size=5,activation='relu'))\n",
    "# model_cnn.add(Conv1D(32,kernel_size=5,activation='relu'))\n",
    "# model_cnn.add(Conv1D(32,kernel_size=5))\n",
    "model_cnn.add(BatchNormalization())\n",
    "model_cnn.add(Dropout(0.2))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(32))\n",
    "model_cnn.add(Dropout(0.2))\n",
    "model_cnn.add(Dense(8))\n",
    "model_cnn.compile(optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "252/252 - 2s - loss: 7.4596 - accuracy: 0.1420 - val_loss: 9.3587 - val_accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "252/252 - 1s - loss: 6.5239 - accuracy: 0.1480 - val_loss: 5.1971 - val_accuracy: 0.1019\n",
      "Epoch 3/100\n",
      "252/252 - 1s - loss: 5.4774 - accuracy: 0.1221 - val_loss: 4.7286 - val_accuracy: 0.1574\n",
      "Epoch 4/100\n",
      "252/252 - 1s - loss: 4.8253 - accuracy: 0.1460 - val_loss: 4.6585 - val_accuracy: 0.1343\n",
      "Epoch 5/100\n",
      "252/252 - 1s - loss: 4.3213 - accuracy: 0.1460 - val_loss: 4.6593 - val_accuracy: 0.1343\n",
      "Epoch 6/100\n",
      "252/252 - 1s - loss: 4.3158 - accuracy: 0.1450 - val_loss: 4.6137 - val_accuracy: 0.1250\n",
      "Epoch 7/100\n",
      "252/252 - 1s - loss: 4.3195 - accuracy: 0.1400 - val_loss: 4.6410 - val_accuracy: 0.1481\n",
      "Epoch 8/100\n",
      "252/252 - 1s - loss: 4.4920 - accuracy: 0.1400 - val_loss: 5.4338 - val_accuracy: 0.1458\n",
      "Epoch 9/100\n",
      "252/252 - 1s - loss: 7.5099 - accuracy: 0.1281 - val_loss: 6.7937 - val_accuracy: 0.1412\n",
      "Epoch 10/100\n",
      "252/252 - 1s - loss: 7.3924 - accuracy: 0.1380 - val_loss: 6.6392 - val_accuracy: 0.1458\n",
      "Epoch 11/100\n",
      "252/252 - 1s - loss: 5.9929 - accuracy: 0.1321 - val_loss: 4.9616 - val_accuracy: 0.1181\n",
      "Epoch 12/100\n",
      "252/252 - 1s - loss: 5.0702 - accuracy: 0.1380 - val_loss: 4.5633 - val_accuracy: 0.1343\n",
      "Epoch 13/100\n",
      "252/252 - 1s - loss: 4.8344 - accuracy: 0.1360 - val_loss: 4.4192 - val_accuracy: 0.1458\n",
      "Epoch 14/100\n",
      "252/252 - 1s - loss: 4.3715 - accuracy: 0.1589 - val_loss: 4.2382 - val_accuracy: 0.1528\n",
      "Epoch 15/100\n",
      "252/252 - 1s - loss: 4.5314 - accuracy: 0.1410 - val_loss: 3.9580 - val_accuracy: 0.1481\n",
      "Epoch 16/100\n",
      "252/252 - 1s - loss: 5.5757 - accuracy: 0.1490 - val_loss: 7.3512 - val_accuracy: 0.1574\n",
      "Epoch 17/100\n",
      "252/252 - 1s - loss: 4.9858 - accuracy: 0.1410 - val_loss: 4.0085 - val_accuracy: 0.1273\n",
      "Epoch 18/100\n",
      "252/252 - 1s - loss: 3.5387 - accuracy: 0.1212 - val_loss: 3.3413 - val_accuracy: 0.1551\n",
      "Epoch 19/100\n",
      "252/252 - 1s - loss: 3.0232 - accuracy: 0.1122 - val_loss: 3.0565 - val_accuracy: 0.1181\n",
      "Epoch 20/100\n",
      "252/252 - 1s - loss: 3.0378 - accuracy: 0.1063 - val_loss: 2.5997 - val_accuracy: 0.1181\n",
      "Epoch 21/100\n",
      "252/252 - 1s - loss: 2.9114 - accuracy: 0.1192 - val_loss: 2.4093 - val_accuracy: 0.1412\n",
      "Epoch 22/100\n",
      "252/252 - 1s - loss: 2.5563 - accuracy: 0.1082 - val_loss: 2.4203 - val_accuracy: 0.1435\n",
      "Epoch 23/100\n",
      "252/252 - 1s - loss: 2.5903 - accuracy: 0.1271 - val_loss: 2.6193 - val_accuracy: 0.1597\n",
      "Epoch 24/100\n",
      "252/252 - 1s - loss: 2.6620 - accuracy: 0.1380 - val_loss: 3.4992 - val_accuracy: 0.1806\n",
      "Epoch 25/100\n",
      "252/252 - 1s - loss: 2.7256 - accuracy: 0.1311 - val_loss: 2.7032 - val_accuracy: 0.1806\n",
      "Epoch 26/100\n",
      "252/252 - 1s - loss: 2.6489 - accuracy: 0.1370 - val_loss: 2.7108 - val_accuracy: 0.1690\n",
      "Epoch 27/100\n",
      "252/252 - 1s - loss: 2.6400 - accuracy: 0.1420 - val_loss: 2.5793 - val_accuracy: 0.1690\n",
      "Epoch 28/100\n",
      "252/252 - 1s - loss: 2.6588 - accuracy: 0.1301 - val_loss: 2.5087 - val_accuracy: 0.1875\n",
      "Epoch 29/100\n",
      "252/252 - 1s - loss: 2.7221 - accuracy: 0.1460 - val_loss: 2.6453 - val_accuracy: 0.1852\n",
      "Epoch 30/100\n",
      "252/252 - 1s - loss: 2.6366 - accuracy: 0.1400 - val_loss: 2.5951 - val_accuracy: 0.1852\n",
      "Epoch 31/100\n",
      "252/252 - 1s - loss: 2.5479 - accuracy: 0.1390 - val_loss: 2.5781 - val_accuracy: 0.1898\n",
      "Epoch 32/100\n",
      "252/252 - 1s - loss: 2.3847 - accuracy: 0.1470 - val_loss: 2.5599 - val_accuracy: 0.1898\n",
      "Epoch 33/100\n",
      "252/252 - 1s - loss: 2.5034 - accuracy: 0.1549 - val_loss: 2.4086 - val_accuracy: 0.1782\n",
      "Epoch 34/100\n",
      "252/252 - 1s - loss: 2.3789 - accuracy: 0.1370 - val_loss: 2.4695 - val_accuracy: 0.1759\n",
      "Epoch 35/100\n",
      "252/252 - 1s - loss: 2.3022 - accuracy: 0.1360 - val_loss: 2.3593 - val_accuracy: 0.1690\n",
      "Epoch 36/100\n",
      "252/252 - 1s - loss: 2.4650 - accuracy: 0.1351 - val_loss: 2.5103 - val_accuracy: 0.1644\n",
      "Epoch 37/100\n",
      "252/252 - 1s - loss: 2.4376 - accuracy: 0.1311 - val_loss: 2.2837 - val_accuracy: 0.1782\n",
      "Epoch 38/100\n",
      "252/252 - 1s - loss: 2.3372 - accuracy: 0.1360 - val_loss: 2.2436 - val_accuracy: 0.1644\n",
      "Epoch 39/100\n",
      "252/252 - 1s - loss: 2.3174 - accuracy: 0.1341 - val_loss: 2.3705 - val_accuracy: 0.1782\n",
      "Epoch 40/100\n",
      "252/252 - 1s - loss: 2.2044 - accuracy: 0.1341 - val_loss: 2.3408 - val_accuracy: 0.1620\n",
      "Epoch 41/100\n",
      "252/252 - 1s - loss: 2.1911 - accuracy: 0.1370 - val_loss: 2.4057 - val_accuracy: 0.1528\n",
      "Epoch 42/100\n",
      "252/252 - 1s - loss: 2.3793 - accuracy: 0.1410 - val_loss: 2.6132 - val_accuracy: 0.1528\n",
      "Epoch 43/100\n",
      "252/252 - 1s - loss: 2.3511 - accuracy: 0.1390 - val_loss: 2.8677 - val_accuracy: 0.1435\n",
      "Epoch 44/100\n",
      "252/252 - 1s - loss: 2.1902 - accuracy: 0.1231 - val_loss: 2.6243 - val_accuracy: 0.1204\n",
      "Epoch 45/100\n",
      "252/252 - 1s - loss: 2.3652 - accuracy: 0.1390 - val_loss: 2.6056 - val_accuracy: 0.1157\n",
      "Epoch 46/100\n",
      "252/252 - 1s - loss: 2.1823 - accuracy: 0.1241 - val_loss: 2.7126 - val_accuracy: 0.1273\n",
      "Epoch 47/100\n",
      "252/252 - 0s - loss: 2.0905 - accuracy: 0.1301 - val_loss: 2.6544 - val_accuracy: 0.1296\n",
      "Epoch 48/100\n",
      "252/252 - 0s - loss: 2.1961 - accuracy: 0.1341 - val_loss: 2.6495 - val_accuracy: 0.1250\n",
      "Epoch 49/100\n",
      "252/252 - 1s - loss: 2.2114 - accuracy: 0.1202 - val_loss: 2.3573 - val_accuracy: 0.1412\n",
      "Epoch 50/100\n",
      "252/252 - 1s - loss: 2.2466 - accuracy: 0.1321 - val_loss: 2.4900 - val_accuracy: 0.1528\n",
      "Epoch 51/100\n",
      "252/252 - 1s - loss: 2.4437 - accuracy: 0.1331 - val_loss: 2.5988 - val_accuracy: 0.1319\n",
      "Epoch 52/100\n",
      "252/252 - 1s - loss: 2.4470 - accuracy: 0.1301 - val_loss: 2.4067 - val_accuracy: 0.1366\n",
      "Epoch 53/100\n",
      "252/252 - 0s - loss: 2.3140 - accuracy: 0.1182 - val_loss: 2.4166 - val_accuracy: 0.1250\n",
      "Epoch 54/100\n",
      "252/252 - 0s - loss: 2.2815 - accuracy: 0.1271 - val_loss: 2.1903 - val_accuracy: 0.1227\n",
      "Epoch 55/100\n",
      "252/252 - 0s - loss: 2.3359 - accuracy: 0.1202 - val_loss: 2.4491 - val_accuracy: 0.1319\n",
      "Epoch 56/100\n",
      "252/252 - 0s - loss: 2.2650 - accuracy: 0.1321 - val_loss: 2.4615 - val_accuracy: 0.1319\n",
      "Epoch 57/100\n",
      "252/252 - 0s - loss: 2.2628 - accuracy: 0.1202 - val_loss: 2.2759 - val_accuracy: 0.1227\n",
      "Epoch 58/100\n",
      "252/252 - 0s - loss: 2.2682 - accuracy: 0.1241 - val_loss: 2.4179 - val_accuracy: 0.1343\n",
      "Epoch 59/100\n",
      "252/252 - 1s - loss: 2.1895 - accuracy: 0.1261 - val_loss: 2.1388 - val_accuracy: 0.1157\n",
      "Epoch 60/100\n",
      "252/252 - 1s - loss: 2.1753 - accuracy: 0.1162 - val_loss: 2.2889 - val_accuracy: 0.1227\n",
      "Epoch 61/100\n",
      "252/252 - 0s - loss: 2.1337 - accuracy: 0.1132 - val_loss: 2.3898 - val_accuracy: 0.1181\n",
      "Epoch 62/100\n",
      "252/252 - 0s - loss: 2.1913 - accuracy: 0.1043 - val_loss: 2.2904 - val_accuracy: 0.1319\n",
      "Epoch 63/100\n",
      "252/252 - 0s - loss: 2.1616 - accuracy: 0.1152 - val_loss: 2.3104 - val_accuracy: 0.1273\n",
      "Epoch 64/100\n",
      "252/252 - 0s - loss: 2.1633 - accuracy: 0.1331 - val_loss: 2.2326 - val_accuracy: 0.1319\n",
      "Epoch 65/100\n",
      "252/252 - 0s - loss: 2.1983 - accuracy: 0.1390 - val_loss: 2.3420 - val_accuracy: 0.1181\n",
      "Epoch 66/100\n",
      "252/252 - 1s - loss: 2.2633 - accuracy: 0.1291 - val_loss: 2.2301 - val_accuracy: 0.1389\n",
      "Epoch 67/100\n",
      "252/252 - 0s - loss: 2.4486 - accuracy: 0.1023 - val_loss: 2.0968 - val_accuracy: 0.1273\n",
      "Epoch 68/100\n",
      "252/252 - 0s - loss: 2.4148 - accuracy: 0.0993 - val_loss: 2.1923 - val_accuracy: 0.0972\n",
      "Epoch 69/100\n",
      "252/252 - 0s - loss: 2.4667 - accuracy: 0.0993 - val_loss: 2.2804 - val_accuracy: 0.1366\n",
      "Epoch 70/100\n",
      "252/252 - 1s - loss: 2.3947 - accuracy: 0.1033 - val_loss: 2.2548 - val_accuracy: 0.0972\n",
      "Epoch 71/100\n",
      "252/252 - 0s - loss: 2.3065 - accuracy: 0.1152 - val_loss: 2.1250 - val_accuracy: 0.0972\n",
      "Epoch 72/100\n",
      "252/252 - 1s - loss: 2.2961 - accuracy: 0.0914 - val_loss: 2.0986 - val_accuracy: 0.0880\n",
      "Epoch 73/100\n",
      "252/252 - 0s - loss: 2.2786 - accuracy: 0.0983 - val_loss: 2.2184 - val_accuracy: 0.0926\n",
      "Epoch 74/100\n",
      "252/252 - 0s - loss: 2.2158 - accuracy: 0.0894 - val_loss: 2.2097 - val_accuracy: 0.1204\n",
      "Epoch 75/100\n",
      "252/252 - 0s - loss: 2.3854 - accuracy: 0.1023 - val_loss: 2.4230 - val_accuracy: 0.1157\n",
      "Epoch 76/100\n",
      "252/252 - 0s - loss: 2.2508 - accuracy: 0.1053 - val_loss: 2.2470 - val_accuracy: 0.1111\n",
      "Epoch 77/100\n",
      "252/252 - 0s - loss: 2.1598 - accuracy: 0.1072 - val_loss: 2.1410 - val_accuracy: 0.1134\n",
      "Epoch 78/100\n",
      "252/252 - 0s - loss: 2.2225 - accuracy: 0.1053 - val_loss: 2.1497 - val_accuracy: 0.1157\n",
      "Epoch 79/100\n",
      "252/252 - 0s - loss: 2.2292 - accuracy: 0.1023 - val_loss: 2.1963 - val_accuracy: 0.1134\n",
      "Epoch 80/100\n",
      "252/252 - 0s - loss: 2.1162 - accuracy: 0.0933 - val_loss: 2.1187 - val_accuracy: 0.1042\n",
      "Epoch 81/100\n",
      "252/252 - 1s - loss: 2.1767 - accuracy: 0.0904 - val_loss: 2.1570 - val_accuracy: 0.1042\n",
      "Epoch 82/100\n",
      "252/252 - 1s - loss: 2.1281 - accuracy: 0.1043 - val_loss: 2.1903 - val_accuracy: 0.1042\n",
      "Epoch 83/100\n",
      "252/252 - 1s - loss: 2.1683 - accuracy: 0.1053 - val_loss: 2.1149 - val_accuracy: 0.0972\n",
      "Epoch 84/100\n",
      "252/252 - 1s - loss: 2.1278 - accuracy: 0.0914 - val_loss: 2.2489 - val_accuracy: 0.0718\n",
      "Epoch 85/100\n",
      "252/252 - 1s - loss: 2.2044 - accuracy: 0.1033 - val_loss: 2.1934 - val_accuracy: 0.1065\n",
      "Epoch 86/100\n",
      "252/252 - 1s - loss: 2.1744 - accuracy: 0.1092 - val_loss: 2.2068 - val_accuracy: 0.0926\n",
      "Epoch 87/100\n",
      "252/252 - 1s - loss: 2.2357 - accuracy: 0.0914 - val_loss: 2.2003 - val_accuracy: 0.1157\n",
      "Epoch 88/100\n",
      "252/252 - 1s - loss: 2.2375 - accuracy: 0.1033 - val_loss: 2.1251 - val_accuracy: 0.1250\n",
      "Epoch 89/100\n",
      "252/252 - 1s - loss: 2.1868 - accuracy: 0.1043 - val_loss: 2.2420 - val_accuracy: 0.1065\n",
      "Epoch 90/100\n",
      "252/252 - 1s - loss: 2.2448 - accuracy: 0.0914 - val_loss: 2.2686 - val_accuracy: 0.1088\n",
      "Epoch 91/100\n",
      "252/252 - 1s - loss: 2.2240 - accuracy: 0.1132 - val_loss: 2.2143 - val_accuracy: 0.1042\n",
      "Epoch 92/100\n",
      "252/252 - 1s - loss: 2.1784 - accuracy: 0.0983 - val_loss: 2.1431 - val_accuracy: 0.1019\n",
      "Epoch 93/100\n",
      "252/252 - 0s - loss: 2.2497 - accuracy: 0.0894 - val_loss: 2.1953 - val_accuracy: 0.1042\n",
      "Epoch 94/100\n",
      "252/252 - 0s - loss: 2.3312 - accuracy: 0.0933 - val_loss: 2.3900 - val_accuracy: 0.0602\n",
      "Epoch 95/100\n",
      "252/252 - 0s - loss: 2.2481 - accuracy: 0.1013 - val_loss: 2.2803 - val_accuracy: 0.1042\n",
      "Epoch 96/100\n",
      "252/252 - 0s - loss: 2.2526 - accuracy: 0.1063 - val_loss: 2.3055 - val_accuracy: 0.0903\n",
      "Epoch 97/100\n",
      "252/252 - 1s - loss: 2.1776 - accuracy: 0.0924 - val_loss: 2.0822 - val_accuracy: 0.0926\n",
      "Epoch 98/100\n",
      "252/252 - 1s - loss: 2.1765 - accuracy: 0.0973 - val_loss: 2.2100 - val_accuracy: 0.0787\n",
      "Epoch 99/100\n",
      "252/252 - 1s - loss: 2.2327 - accuracy: 0.1112 - val_loss: 2.1854 - val_accuracy: 0.0972\n",
      "Epoch 100/100\n",
      "252/252 - 1s - loss: 2.1802 - accuracy: 0.0933 - val_loss: 2.1613 - val_accuracy: 0.0949\n"
     ]
    }
   ],
   "source": [
    "tb = time_for_batch()\n",
    "te = time_for_epoch()\n",
    "\n",
    "history = model_cnn.fit(X_train_cnn, Y_train_cnn,\n",
    "                      batch_size=4,\n",
    "                      epochs=100,\n",
    "                      verbose=2,\n",
    "                      use_multiprocessing=False,\n",
    "                      callbacks = [tb, te],\n",
    "                      validation_data=(X_test_cnn, Y_test_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
